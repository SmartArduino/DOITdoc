

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Python Machine Learning - Code Examples &mdash; BookData 0.1 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="BookData 0.1 documentation" href="../../index.html"/> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html" class="icon icon-home"> BookData
          

          
          </a>

          
            
            
              <div class="version">
                0.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../../beginning/index.html">入门篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../base/index.html">基础篇</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tools/index.html">工具篇</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../../index.html">BookData</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Docs</a> &raquo;</li>
      
    <li>Python Machine Learning - Code Examples</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../_sources/rasbt_py_ml_book/ch08/ch08.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput > div,
div.nbinput div[class^=highlight],
div.nbinput div[class^=highlight] pre,
div.nboutput,
div.nboutput > div,
div.nboutput div[class^=highlight],
div.nboutput div[class^=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class^=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput > :first-child pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput > :first-child pre {
    color: #D84315;
}

/* all prompts */
div.nbinput > :first-child[class^=highlight],
div.nboutput > :first-child[class^=highlight],
div.nboutput > :first-child {
    min-width: 9ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}

/* input/output area */
div.nbinput > :nth-child(2)[class^=highlight],
div.nboutput > :nth-child(2),
div.nboutput > :nth-child(2)[class^=highlight] {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}

/* input area */
div.nbinput > :nth-child(2)[class^=highlight] {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput  > :nth-child(2).stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<p>Copyright (c) 2015, 2016 <a class="reference external" href="sebastianraschka.com">Sebastian Raschka</a></p>
<p><a class="reference external" href="https://github.com/rasbt/python-machine-learning-book">https://github.com/rasbt/python-machine-learning-book</a></p>
<p><a class="reference external" href="https://github.com/rasbt/python-machine-learning-book/blob/master/LICENSE.txt">MIT
License</a></p>
<div class="section" id="Python-Machine-Learning---Code-Examples">
<h1>Python Machine Learning - Code Examples<a class="headerlink" href="#Python-Machine-Learning---Code-Examples" title="Permalink to this headline">¶</a></h1>
</div>
<div class="section" id="Chapter-8---Applying-Machine-Learning-To-Sentiment-Analysis">
<h1>Chapter 8 - Applying Machine Learning To Sentiment Analysis<a class="headerlink" href="#Chapter-8---Applying-Machine-Learning-To-Sentiment-Analysis" title="Permalink to this headline">¶</a></h1>
<p>Note that the optional watermark extension is a small IPython notebook
plugin that I developed to make the code reproducible. You can just skip
the following line(s).</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="o">%</span><span class="k">load_ext</span> watermark
<span class="o">%</span><span class="k">watermark</span> -a &#39;Sebastian Raschka&#39; -u -d -v -p numpy,pandas,matplotlib,scikit-learn,nltk
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
The watermark extension is already loaded. To reload it, use:
  %reload_ext watermark
Sebastian Raschka
last updated: 2016-06-30

CPython 3.5.1
IPython 4.2.0

numpy 1.11.0
pandas 0.18.1
matplotlib 1.5.1
scikit-learn 0.17.1
nltk 3.2.1
</pre></div></div>
</div>
<p><em>The use of ``watermark`` is optional. You can install this IPython
extension via &#8220;``pip install watermark``&#8221;. For more information, please
see: https://github.com/rasbt/watermark.</em></p>
<div class="section" id="Overview">
<h2>Overview<a class="headerlink" href="#Overview" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><a class="reference external" href="#Obtaining-the-IMDb-movie-review-dataset">Obtaining the IMDb movie review
dataset</a></li>
<li><a class="reference external" href="#Introducing-the-bag-of-words-model">Introducing the bag-of-words
model</a></li>
<li><a class="reference external" href="#Transforming-words-into-feature-vectors">Transforming words into feature
vectors</a></li>
<li><a class="reference external" href="#Assessing-word-relevancy-via-term-frequency-inverse-document-frequency">Assessing word relevancy via term frequency-inverse document
frequency</a></li>
<li><a class="reference external" href="#Cleaning-text-data">Cleaning text data</a></li>
<li><a class="reference external" href="#Processing-documents-into-tokens">Processing documents into
tokens</a></li>
<li><a class="reference external" href="#Training-a-logistic-regression-model-for-document-classification">Training a logistic regression model for document
classification</a></li>
<li><a class="reference external" href="#Working-with-bigger-data-–-online-algorithms-and-out-of-core-learning">Working with bigger data – online algorithms and out-of-core
learning</a></li>
<li><a class="reference external" href="#Summary">Summary</a></li>
</ul>
</div>
</div>
<div class="section" id="Obtaining-the-IMDb-movie-review-dataset">
<h1>Obtaining the IMDb movie review dataset<a class="headerlink" href="#Obtaining-the-IMDb-movie-review-dataset" title="Permalink to this headline">¶</a></h1>
<p>The IMDB movie review set can be downloaded from
<a class="reference external" href="http://ai.stanford.edu/~amaas/data/sentiment/">http://ai.stanford.edu/~amaas/data/sentiment/</a>. After downloading the
dataset, decompress the files.</p>
<ol class="upperalpha simple">
<li>If you are working with Linux or MacOS X, open a new terminal windowm
<code class="docutils literal"><span class="pre">cd</span></code> into the download directory and execute</li>
</ol>
<p><code class="docutils literal"><span class="pre">tar</span> <span class="pre">-zxf</span> <span class="pre">aclImdb_v1.tar.gz</span></code></p>
<ol class="upperalpha simple" start="2">
<li>If you are working with Windows, download an archiver such as
<a class="reference external" href="http://www.7-zip.org">7Zip</a> to extract the files from the
download archive.</li>
</ol>
<div class="section" id="Compatibility-Note:">
<h2>Compatibility Note:<a class="headerlink" href="#Compatibility-Note:" title="Permalink to this headline">¶</a></h2>
<p>I received an email from a reader who was having troubles with reading
the movie review texts due to encoding issues. Typically, Python&#8217;s
default encoding is set to <code class="docutils literal"><span class="pre">'utf-8'</span></code>, which shouldn&#8217;t cause troubles
when running this IPython notebook. You can simply check the encoding on
your machine by firing up a new Python interpreter from the command line
terminal and execute</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sys</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sys</span><span class="o">.</span><span class="n">getdefaultencoding</span><span class="p">()</span>
</pre></div>
</div>
<p>If the returned result is <strong>not</strong> <code class="docutils literal"><span class="pre">'utf-8'</span></code>, you probably need to
change your Python&#8217;s encoding to <code class="docutils literal"><span class="pre">'utf-8'</span></code>, for example by typing
<code class="docutils literal"><span class="pre">export</span> <span class="pre">PYTHONIOENCODING=utf8</span></code> in your terminal shell prior to running
this IPython notebook. (Note that this is a temporary change, and it
needs to be executed in the same shell that you&#8217;ll use to launch
<code class="docutils literal"><span class="pre">ipython</span> <span class="pre">notebook</span></code>.</p>
<p>Alternatively, you can replace the lines</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">infile</span><span class="p">:</span>
<span class="o">...</span>
<span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./movie_data.csv&#39;</span><span class="p">)</span>
<span class="o">...</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;./movie_data.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>by</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">infile</span><span class="p">:</span>
<span class="o">...</span>
<span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./movie_data.csv&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="o">...</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;./movie_data.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>in the following cells to achieve the desired effect.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pyprind</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">os</span>

<span class="c1"># change the `basepath` to the directory of the</span>
<span class="c1"># unzipped movie dataset</span>

<span class="c1">#basepath = &#39;/Users/Sebastian/Desktop/aclImdb/&#39;</span>
<span class="n">basepath</span> <span class="o">=</span> <span class="s1">&#39;./aclImdb&#39;</span>

<span class="n">labels</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;pos&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">:</span> <span class="mi">0</span><span class="p">}</span>
<span class="n">pbar</span> <span class="o">=</span> <span class="n">pyprind</span><span class="o">.</span><span class="n">ProgBar</span><span class="p">(</span><span class="mi">50000</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="p">(</span><span class="s1">&#39;pos&#39;</span><span class="p">,</span> <span class="s1">&#39;neg&#39;</span><span class="p">):</span>
        <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">basepath</span><span class="p">,</span> <span class="n">s</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">file</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">file</span><span class="p">),</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">infile</span><span class="p">:</span>
                <span class="n">txt</span> <span class="o">=</span> <span class="n">infile</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">append</span><span class="p">([[</span><span class="n">txt</span><span class="p">,</span> <span class="n">labels</span><span class="p">[</span><span class="n">l</span><span class="p">]]],</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
<span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">,</span> <span class="s1">&#39;sentiment&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="stderr container">
<div class="highlight"><pre>
0%                          100%
[##############################] | ETA: 00:00:00
Total time elapsed: 00:06:23
</pre></div></div>
</div>
<p>Shuffling the DataFrame:</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">reindex</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">))</span>
</pre></div>
</div>
</div>
<p>Optional: Saving the assembled data as CSV file:</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;./movie_data.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./movie_data.csv&#39;</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[6]:
</pre></div>
</div>
<div class="container">
<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review</th>
      <th>sentiment</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>OK... so... I really like Kris Kristofferson a...</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>***SPOILER*** Do not read this, if you think a...</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<hr></div>
<div class="section" id="Note">
<h2>Note<a class="headerlink" href="#Note" title="Permalink to this headline">¶</a></h2>
<p>If you have problems with creating the <code class="docutils literal"><span class="pre">movie_data.csv</span></code> file in the
previous chapter, you can find a download a zip archive at
<a class="reference external" href="https://github.com/rasbt/python-machine-learning-book/tree/master/code/datasets/movie">https://github.com/rasbt/python-machine-learning-book/tree/master/code/datasets/movie</a></p>
<hr></div>
</div>
<div class="section" id="Introducing-the-bag-of-words-model">
<h1>Introducing the bag-of-words model<a class="headerlink" href="#Introducing-the-bag-of-words-model" title="Permalink to this headline">¶</a></h1>
<p>...</p>
<p>By calling the fit_transform method on CountVectorizer, we just
constructed the vocabulary of the bag-of-words model and transformed the
following three sentences into sparse feature vectors: 1. The sun is
shining 2. The weather is sweet 3. The sun is shining, the weather is
sweet, and one and one is two</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">CountVectorizer</span>
<span class="n">count</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
        <span class="s1">&#39;The sun is shining&#39;</span><span class="p">,</span>
        <span class="s1">&#39;The weather is sweet&#39;</span><span class="p">,</span>
        <span class="s1">&#39;The sun is shining, the weather is sweet, and one and one is two&#39;</span><span class="p">])</span>
<span class="n">bag</span> <span class="o">=</span> <span class="n">count</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Now let us print the contents of the vocabulary to get a better
understanding of the underlying concepts:</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [8]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">count</span><span class="o">.</span><span class="n">vocabulary_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
{&#39;sun&#39;: 4, &#39;and&#39;: 0, &#39;is&#39;: 1, &#39;the&#39;: 6, &#39;shining&#39;: 3, &#39;two&#39;: 7, &#39;sweet&#39;: 5, &#39;weather&#39;: 8, &#39;one&#39;: 2}
</pre></div></div>
</div>
<p>As we can see from executing the preceding command, the vocabulary is
stored in a Python dictionary, which maps the unique words that are
mapped to integer indices. Next let us print the feature vectors that we
just created:</p>
<p>Each index position in the feature vectors shown here corresponds to the
integer values that are stored as dictionary items in the
CountVectorizer vocabulary. For example, the rst feature at index
position 0 resembles the count of the word and, which only occurs in the
last document, and the word is at index position 1 (the 2nd feature in
the document vectors) occurs in all three sentences. Those values in the
feature vectors are also called the raw term frequencies: <em>tf (t,d)</em>—the
number of times a term t occurs in a document <em>d</em>.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">bag</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
[[0 1 0 1 1 0 1 0 0]
 [0 1 0 0 0 1 1 0 1]
 [2 3 2 1 1 1 2 1 1]]
</pre></div></div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>When we are analyzing text data, we often encounter words that occur
across multiple documents from both classes. Those frequently occurring
words typically don&#8217;t contain useful or discriminatory information. In
this subsection, we will learn about a useful technique called term
frequency-inverse document frequency (tf-idf) that can be used to
downweight those frequently occurring words in the feature vectors. The
tf-idf can be de ned as the product of the term frequency and the
inverse document frequency:</p>
<div class="math">
\[\text{tf-idf}(t,d)=\text{tf (t,d)}\times \text{idf}(t,d)\]</div>
<p>Here the tf(t, d) is the term frequency that we introduced in the
previous section, and the inverse document frequency <em>idf(t, d)</em> can be
calculated as:</p>
<div class="math">
\[\text{idf}(t,d) = \text{log}\frac{n_d}{1+\text{df}(d, t)},\]</div>
<p>where <span class="math">\(n_d\)</span> is the total number of documents, and <em>df(d, t)</em> is
the number of documents <em>d</em> that contain the term <em>t</em>. Note that adding
the constant 1 to the denominator is optional and serves the purpose of
assigning a non-zero value to terms that occur in all training samples;
the log is used to ensure that low document frequencies are not given
too much weight.</p>
<p>Scikit-learn implements yet another transformer, the
<code class="docutils literal"><span class="pre">TfidfTransformer</span></code>, that takes the raw term frequencies from
<code class="docutils literal"><span class="pre">CountVectorizer</span></code> as input and transforms them into tf-idfs:</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">TfidfTransformer</span>

<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">(</span><span class="n">use_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">smooth_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tfidf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">count</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">))</span><span class="o">.</span><span class="n">toarray</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
[[ 0.    0.43  0.    0.56  0.56  0.    0.43  0.    0.  ]
 [ 0.    0.43  0.    0.    0.    0.56  0.43  0.    0.56]
 [ 0.5   0.45  0.5   0.19  0.19  0.19  0.3   0.25  0.19]]
</pre></div></div>
</div>
<p>As we saw in the previous subsection, the word is had the largest term
frequency in the 3rd document, being the most frequently occurring word.
However, after transforming the same feature vector into tf-idfs, we see
that the word is is now associated with a relatively small tf-idf (0.45)
in document 3 since it is also contained in documents 1 and 2 and thus
is unlikely to contain any useful, discriminatory information.</p>
<p>However, if we&#8217;d manually calculated the tf-idfs of the individual terms
in our feature vectors, we&#8217;d have noticed that the <code class="docutils literal"><span class="pre">TfidfTransformer</span></code>
calculates the tf-idfs slightly differently compared to the standard
textbook equations that we de ned earlier. The equations for the idf and
tf-idf that were implemented in scikit-learn are:</p>
<div class="math">
\[\text{idf} (t,d) = log\frac{1 + n_d}{1 + \text{df}(d, t)}\]</div>
<p>The tf-idf equation that was implemented in scikit-learn is as follows:</p>
<div class="math">
\[\text{tf-idf}(t,d) = \text{tf}(t,d) \times (\text{idf}(t,d)+1)\]</div>
<p>While it is also more typical to normalize the raw term frequencies
before calculating the tf-idfs, the <code class="docutils literal"><span class="pre">TfidfTransformer</span></code> normalizes the
tf-idfs directly.</p>
<p>By default (<code class="docutils literal"><span class="pre">norm='l2'</span></code>), scikit-learn&#8217;s TfidfTransformer applies the
L2-normalization, which returns a vector of length 1 by dividing an
un-normalized feature vector <em>v</em> by its L2-norm:</p>
<div class="math">
\[v_{\text{norm}} = \frac{v}{||v||_2} = \frac{v}{\sqrt{v_{1}^{2} + v_{2}^{2} + \dots + v_{n}^{2}}} = \frac{v}{\big (\sum_{i=1}^{n} v_{i}^{2}\big)^\frac{1}{2}}\]</div>
<p>To make sure that we understand how TfidfTransformer works, let us walk
through an example and calculate the tf-idf of the word is in the 3rd
document.</p>
<p>The word is has a term frequency of 3 (tf = 3) in document 3, and the
document frequency of this term is 3 since the term is occurs in all
three documents (df = 3). Thus, we can calculate the idf as follows:</p>
<div class="math">
\[\text{idf}(&quot;is&quot;, d3) = log \frac{1+3}{1+3} = 0\]</div>
<p>Now in order to calculate the tf-idf, we simply need to add 1 to the
inverse document frequency and multiply it by the term frequency:</p>
<div class="math">
\[\text{tf-idf}(&quot;is&quot;,d3)= 3 \times (0+1) = 3\]</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">tf_is</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">n_docs</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">idf_is</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">((</span><span class="n">n_docs</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">3</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
<span class="n">tfidf_is</span> <span class="o">=</span> <span class="n">tf_is</span> <span class="o">*</span> <span class="p">(</span><span class="n">idf_is</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;tf-idf of term &quot;is&quot; = </span><span class="si">%.2f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">tfidf_is</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
tf-idf of term &#34;is&#34; = 3.00
</pre></div></div>
</div>
<p>If we repeated these calculations for all terms in the 3rd document,
we&#8217;d obtain the following tf-idf vectors: [3.39, 3.0, 3.39, 1.29, 1.29,
1.29, 2.0 , 1.69, 1.29]. However, we notice that the values in this
feature vector are different from the values that we obtained from the
TfidfTransformer that we used previously. The nal step that we are
missing in this tf-idf calculation is the L2-normalization, which can be
applied as follows:</p>
<div class="math">
\[\text{tfi-df}_{norm} = \frac{[3.39, 3.0, 3.39, 1.29, 1.29, 1.29, 2.0 , 1.69, 1.29]}{\sqrt{[3.39^2, 3.0^2, 3.39^2, 1.29^2, 1.29^2, 1.29^2, 2.0^2 , 1.69^2, 1.29^2]}}\]</div>
<div class="math">
\[=[0.5, 0.45, 0.5, 0.19, 0.19, 0.19, 0.3, 0.25, 0.19]\]</div>
<div class="math">
\[\Rightarrow \text{tfi-df}_{norm}(&quot;is&quot;, d3) = 0.45\]</div>
<p>As we can see, the results match the results returned by scikit-learn&#8217;s
<code class="docutils literal"><span class="pre">TfidfTransformer</span></code> (below). Since we now understand how tf-idfs are
calculated, let us proceed to the next sections and apply those concepts
to the movie review dataset.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [13]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfTransformer</span><span class="p">(</span><span class="n">use_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">smooth_idf</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">raw_tfidf</span> <span class="o">=</span> <span class="n">tfidf</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">count</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">docs</span><span class="p">))</span><span class="o">.</span><span class="n">toarray</span><span class="p">()[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">raw_tfidf</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[13]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>array([ 3.39,  3.  ,  3.39,  1.29,  1.29,  1.29,  2.  ,  1.69,  1.29])
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [14]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">l2_tfidf</span> <span class="o">=</span> <span class="n">raw_tfidf</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">raw_tfidf</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="n">l2_tfidf</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[14]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>array([ 0.5 ,  0.45,  0.5 ,  0.19,  0.19,  0.19,  0.3 ,  0.25,  0.19])
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [15]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;review&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">50</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[15]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>&#39;is seven.&lt;br /&gt;&lt;br /&gt;Title (Brazil): Not Available&#39;
</pre></div>
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [16]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="k">def</span> <span class="nf">preprocessor</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;&lt;[^&gt;]*&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">emoticons</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;(?::|;|=)(?:-)?(?:\)|\(|D|P)&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[\W]+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span> <span class="o">+</span>\
        <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">emoticons</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">text</span>
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [17]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">preprocessor</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;review&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">50</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[17]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>&#39;is seven title brazil not available&#39;
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [18]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">preprocessor</span><span class="p">(</span><span class="s2">&quot;&lt;/a&gt;This :) is :( a test :-)!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[18]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>&#39;this is a test :) :( :)&#39;
</pre></div>
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [19]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">df</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">preprocessor</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [20]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">nltk.stem.porter</span> <span class="k">import</span> <span class="n">PorterStemmer</span>

<span class="n">porter</span> <span class="o">=</span> <span class="n">PorterStemmer</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>


<span class="k">def</span> <span class="nf">tokenizer_porter</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">porter</span><span class="o">.</span><span class="n">stem</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [21]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">tokenizer</span><span class="p">(</span><span class="s1">&#39;runners like running and thus they run&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[21]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>[&#39;runners&#39;, &#39;like&#39;, &#39;running&#39;, &#39;and&#39;, &#39;thus&#39;, &#39;they&#39;, &#39;run&#39;]
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [22]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">tokenizer_porter</span><span class="p">(</span><span class="s1">&#39;runners like running and thus they run&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[22]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>[&#39;runner&#39;, &#39;like&#39;, &#39;run&#39;, &#39;and&#39;, &#39;thu&#39;, &#39;they&#39;, &#39;run&#39;]
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [23]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">nltk</span>

<span class="n">nltk</span><span class="o">.</span><span class="n">download</span><span class="p">(</span><span class="s1">&#39;stopwords&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
[nltk_data] Downloading package stopwords to
[nltk_data]     /Users/Sebastian/nltk_data...
[nltk_data]   Package stopwords is already up-to-date!
</pre></div></div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[23]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>True
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [24]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="k">import</span> <span class="n">stopwords</span>

<span class="n">stop</span> <span class="o">=</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s1">&#39;english&#39;</span><span class="p">)</span>
<span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">tokenizer_porter</span><span class="p">(</span><span class="s1">&#39;a runner likes running and runs a lot&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>
<span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[24]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>[&#39;runner&#39;, &#39;like&#39;, &#39;run&#39;, &#39;run&#39;, &#39;lot&#39;]
</pre></div>
</div>
</div>
</div>
<div class="section" id="Training-a-logistic-regression-model-for-document-classification">
<h1>Training a logistic regression model for document classification<a class="headerlink" href="#Training-a-logistic-regression-model-for-document-classification" title="Permalink to this headline">¶</a></h1>
<p>Strip HTML and punctuation to speed up the GridSearch later:</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [25]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span><span class="mi">25000</span><span class="p">,</span> <span class="s1">&#39;review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:</span><span class="mi">25000</span><span class="p">,</span> <span class="s1">&#39;sentiment&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">25000</span><span class="p">:,</span> <span class="s1">&#39;review&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">25000</span><span class="p">:,</span> <span class="s1">&#39;sentiment&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [28]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.grid_search</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="k">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">TfidfVectorizer</span>

<span class="n">tfidf</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">strip_accents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                        <span class="n">lowercase</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                        <span class="n">preprocessor</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">[{</span><span class="s1">&#39;vect__ngram_range&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
               <span class="s1">&#39;vect__stop_words&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">stop</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
               <span class="s1">&#39;vect__tokenizer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">tokenizer_porter</span><span class="p">],</span>
               <span class="s1">&#39;clf__penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">],</span>
               <span class="s1">&#39;clf__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]},</span>
              <span class="p">{</span><span class="s1">&#39;vect__ngram_range&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
               <span class="s1">&#39;vect__stop_words&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">stop</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
               <span class="s1">&#39;vect__tokenizer&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">tokenizer_porter</span><span class="p">],</span>
               <span class="s1">&#39;vect__use_idf&#39;</span><span class="p">:[</span><span class="kc">False</span><span class="p">],</span>
               <span class="s1">&#39;vect__norm&#39;</span><span class="p">:[</span><span class="kc">None</span><span class="p">],</span>
               <span class="s1">&#39;clf__penalty&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="s1">&#39;l2&#39;</span><span class="p">],</span>
               <span class="s1">&#39;clf__C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">100.0</span><span class="p">]},</span>
              <span class="p">]</span>

<span class="n">lr_tfidf</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;vect&#39;</span><span class="p">,</span> <span class="n">tfidf</span><span class="p">),</span>
                     <span class="p">(</span><span class="s1">&#39;clf&#39;</span><span class="p">,</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))])</span>

<span class="n">gs_lr_tfidf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">lr_tfidf</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span>
                           <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;accuracy&#39;</span><span class="p">,</span>
                           <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                           <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                           <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [29]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">gs_lr_tfidf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
Fitting 5 folds for each of 48 candidates, totalling 240 fits
</pre></div></div>
</div>
<div class="nboutput container">
<div class="container">
</div>
<div class="stderr container">
<div class="highlight"><pre>
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed: 12.0min
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 53.2min
[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 69.4min finished
</pre></div></div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[29]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>GridSearchCV(cv=5, error_score=&#39;raise&#39;,
       estimator=Pipeline(steps=[(&#39;vect&#39;, TfidfVectorizer(analyzer=&#39;word&#39;, binary=False, decode_error=&#39;strict&#39;,
        dtype=&lt;class &#39;numpy.int64&#39;&gt;, encoding=&#39;utf-8&#39;, input=&#39;content&#39;,
        lowercase=False, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), norm=&#39;l2&#39;, preprocessor=None, smooth_idf=True,
 ...nalty=&#39;l2&#39;, random_state=0, solver=&#39;liblinear&#39;, tol=0.0001,
          verbose=0, warm_start=False))]),
       fit_params={}, iid=True, n_jobs=-1,
       param_grid=[{&#39;vect__tokenizer&#39;: [&lt;function tokenizer at 0x111594400&gt;, &lt;function tokenizer_porter at 0x111594488&gt;], &#39;vect__ngram_range&#39;: [(1, 1)], &#39;clf__C&#39;: [1.0, 10.0, 100.0], &#39;clf__penalty&#39;: [&#39;l1&#39;, &#39;l2&#39;], &#39;vect__stop_words&#39;: [[&#39;i&#39;, &#39;me&#39;, &#39;my&#39;, &#39;myself&#39;, &#39;we&#39;, &#39;our&#39;, &#39;ours&#39;, &#39;ourselves&#39;, &#39;you&#39;, &#39;you...kenizer at 0x111594400&gt;, &lt;function tokenizer_porter at 0x111594488&gt;], &#39;clf__penalty&#39;: [&#39;l1&#39;, &#39;l2&#39;]}],
       pre_dispatch=&#39;2*n_jobs&#39;, refit=True, scoring=&#39;accuracy&#39;, verbose=1)
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [30]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best parameter set: </span><span class="si">%s</span><span class="s1"> &#39;</span> <span class="o">%</span> <span class="n">gs_lr_tfidf</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;CV Accuracy: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">gs_lr_tfidf</span><span class="o">.</span><span class="n">best_score_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
Best parameter set: {&#39;vect__tokenizer&#39;: &lt;function tokenizer at 0x111594400&gt;, &#39;vect__ngram_range&#39;: (1, 1), &#39;clf__C&#39;: 10.0, &#39;clf__penalty&#39;: &#39;l2&#39;, &#39;vect__stop_words&#39;: None}
CV Accuracy: 0.897
</pre></div></div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [31]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">gs_lr_tfidf</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Test Accuracy: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
Test Accuracy: 0.899
</pre></div></div>
</div>
<hr><hr><p>Please note that <code class="docutils literal"><span class="pre">gs_lr_tfidf.best_score_</span></code> is the average k-fold
cross-validation score. I.e., if we have a <code class="docutils literal"><span class="pre">GridSearchCV</span></code> object with
5-fold cross-validation (like the one above), the <code class="docutils literal"><span class="pre">best_score_</span></code>
attribute returns the average score over the 5-folds of the best model.
To illustrate this with an example:</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [38]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="k">import</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">6</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">25</span><span class="p">)]</span>
<span class="n">X</span> <span class="o">=</span> <span class="p">(</span><span class="n">y</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">25</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">cv5_idx</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">cross_val_score</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv5_idx</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[38]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>array([ 0.6,  0.4,  0.6,  0.2,  0.6])
</pre></div>
</div>
</div>
<p>By executing the code above, we created a simple data set of random
integers that shall represent our class labels. Next, we fed the indices
of 5 cross-validation folds (<code class="docutils literal"><span class="pre">cv3_idx</span></code>) to the <code class="docutils literal"><span class="pre">cross_val_score</span></code>
scorer, which returned 5 accuracy scores &#8211; these are the 5 accuracy
values for the 5 test folds.</p>
<p>Next, let us use the <code class="docutils literal"><span class="pre">GridSearchCV</span></code> object and feed it the same 5
cross-validation sets (via the pre-generated <code class="docutils literal"><span class="pre">cv3_idx</span></code> indices):</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [39]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.grid_search</span> <span class="k">import</span> <span class="n">GridSearchCV</span>
<span class="n">gs</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(),</span> <span class="p">{},</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv5_idx</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
Fitting 5 folds for each of 1 candidates, totalling 5 fits
[CV]  ................................................................
[CV] ....................................... , score=0.600000 -   0.0s
[CV]  ................................................................
[CV] ....................................... , score=0.400000 -   0.0s
[CV]  ................................................................
[CV] ....................................... , score=0.600000 -   0.0s
[CV]  ................................................................
[CV] ....................................... , score=0.200000 -   0.0s
[CV]  ................................................................
[CV] ....................................... , score=0.600000 -   0.0s
</pre></div></div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="stderr container">
<div class="highlight"><pre>
[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished
</pre></div></div>
</div>
<p>As we can see, the scores for the 5 folds are exactly the same as the
ones from <code class="docutils literal"><span class="pre">cross_val_score</span></code> earlier.</p>
<p>Now, the best_score_ attribute of the <code class="docutils literal"><span class="pre">GridSearchCV</span></code> object, which
becomes available after <code class="docutils literal"><span class="pre">fit</span></code>ting, returns the average accuracy
score of the best model:</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [40]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">gs</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[40]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>0.47999999999999998
</pre></div>
</div>
</div>
<p>As we can see, the result above is consistent with the average score
computed the <code class="docutils literal"><span class="pre">cross_val_score</span></code>.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [41]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv5_idx</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[41]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>0.47999999999999998
</pre></div>
</div>
</div>
<hr><hr></div>
<div class="section" id="Working-with-bigger-data---online-algorithms-and-out-of-core-learning">
<h1>Working with bigger data - online algorithms and out-of-core learning<a class="headerlink" href="#Working-with-bigger-data---online-algorithms-and-out-of-core-learning" title="Permalink to this headline">¶</a></h1>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [32]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="k">import</span> <span class="n">stopwords</span>

<span class="k">def</span> <span class="nf">tokenizer</span><span class="p">(</span><span class="n">text</span><span class="p">):</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;&lt;[^&gt;]*&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">text</span><span class="p">)</span>
    <span class="n">emoticons</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="s1">&#39;(?::|;|=)(?:-)?(?:\)|\(|D|P)&#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
    <span class="n">text</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[\W]+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">text</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span> <span class="o">+</span>\
        <span class="s1">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">emoticons</span><span class="p">)</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;-&#39;</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">)</span>
    <span class="n">tokenized</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stop</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">tokenized</span>


<span class="k">def</span> <span class="nf">stream_docs</span><span class="p">(</span><span class="n">path</span><span class="p">):</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">csv</span><span class="p">:</span>
        <span class="nb">next</span><span class="p">(</span><span class="n">csv</span><span class="p">)</span>  <span class="c1"># skip header</span>
        <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">csv</span><span class="p">:</span>
            <span class="n">text</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">line</span><span class="p">[:</span><span class="o">-</span><span class="mi">3</span><span class="p">],</span> <span class="nb">int</span><span class="p">(</span><span class="n">line</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">])</span>
            <span class="k">yield</span> <span class="n">text</span><span class="p">,</span> <span class="n">label</span>
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [33]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="nb">next</span><span class="p">(</span><span class="n">stream_docs</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s1">&#39;./movie_data.csv&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>Out[33]:
</pre></div>
</div>
<div class="highlight-none"><div class="highlight"><pre>
<span></span>(&#39;&quot;In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\&#39;s, they discover the criminal and a net of power and money to cover the murder.&lt;br /&gt;&lt;br /&gt;&quot;&quot;Murder in Greenwich&quot;&quot; is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.&lt;br /&gt;&lt;br /&gt;Title (Brazil): Not Available&quot;&#39;,
 1)
</pre></div>
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [34]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">get_minibatch</span><span class="p">(</span><span class="n">doc_stream</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
    <span class="n">docs</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size</span><span class="p">):</span>
            <span class="n">text</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">doc_stream</span><span class="p">)</span>
            <span class="n">docs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
            <span class="n">y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">StopIteration</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span>
    <span class="k">return</span> <span class="n">docs</span><span class="p">,</span> <span class="n">y</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [35]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="k">import</span> <span class="n">HashingVectorizer</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">SGDClassifier</span>

<span class="n">vect</span> <span class="o">=</span> <span class="n">HashingVectorizer</span><span class="p">(</span><span class="n">decode_error</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span>
                         <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="o">**</span><span class="mi">21</span><span class="p">,</span>
                         <span class="n">preprocessor</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                         <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>

<span class="n">clf</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">doc_stream</span> <span class="o">=</span> <span class="n">stream_docs</span><span class="p">(</span><span class="n">path</span><span class="o">=</span><span class="s1">&#39;./movie_data.csv&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [36]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pyprind</span>
<span class="n">pbar</span> <span class="o">=</span> <span class="n">pyprind</span><span class="o">.</span><span class="n">ProgBar</span><span class="p">(</span><span class="mi">45</span><span class="p">)</span>

<span class="n">classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">45</span><span class="p">):</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">get_minibatch</span><span class="p">(</span><span class="n">doc_stream</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">X_train</span><span class="p">:</span>
        <span class="k">break</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">classes</span><span class="o">=</span><span class="n">classes</span><span class="p">)</span>
    <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="stderr container">
<div class="highlight"><pre>
0%                          100%
[##############################] | ETA: 00:00:00
Total time elapsed: 00:00:33
</pre></div></div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [37]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">get_minibatch</span><span class="p">(</span><span class="n">doc_stream</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">vect</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Accuracy: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
Accuracy: 0.868
</pre></div></div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [38]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">partial_fit</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Summary">
<h1>Summary<a class="headerlink" href="#Summary" title="Permalink to this headline">¶</a></h1>
</div>


           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Scott Ming.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'0.1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>